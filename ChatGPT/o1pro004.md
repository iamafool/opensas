Below is an **illustrative**, self-contained example showing how you might implement **`INPUT`** and **`DATALINES`** statements in your SAS interpreter. The example includes:

1. **New tokens** for `INPUT` and `DATALINES`.
2. **Lexer** updates to recognize those tokens.
3. **Parser** logic to handle `input var1 <var2 ...>` and `datalines; <lines> ;`.
4. **Interpreter** logic to read the declared variables in `INPUT` and populate rows from the lines in `DATALINES`.
5. **A GTest** example verifying that you can parse and interpret a small data step using `input` and `datalines`.

> **Important:** This code is a **skeletal demonstration**. In production, you will integrate these ideas into your existing files (`Lexer.cpp`, `Parser.cpp`, etc.). The code is simplified to highlight the new features (`INPUT`, `DATALINES`). You should **adapt** it to your actual architecture, error handling, logging, etc.

---

# 1. Tokens and Lexer

We introduce two new token types:
- `KEYWORD_INPUT`
- `KEYWORD_DATALINES`

Your `TokenType` enum might look like this (excerpt only):
```cpp
// Token.h
#ifndef TOKEN_H
#define TOKEN_H

#include <string>

enum class TokenType {
    IDENTIFIER,
    NUMBER,
    STRING,

    // Statements
    KEYWORD_DATA,
    KEYWORD_RUN,
    KEYWORD_OUTPUT,
    KEYWORD_IF,
    KEYWORD_THEN,
    KEYWORD_ELSE,
    KEYWORD_INPUT,      // <--- NEW
    KEYWORD_DATALINES,  // <--- NEW
    // etc...

    EQUAL,
    SEMICOLON,
    LPAREN,
    RPAREN,
    COMMA,
    // ...
    
    EOF_TOKEN,
    UNKNOWN
};

struct Token {
    TokenType type;
    std::string text;
    int line;
    int col;
};

#endif // TOKEN_H
```

Then, **in your lexer**, detect `"input"` and `"datalines"` similarly to how you detect `"data"`, `"run"`, etc. For example (simplified):

```cpp
// Lexer.cpp (excerpt)
#include "Lexer.h"
#include <cctype>
#include <stdexcept>
#include <algorithm>

Lexer::Lexer(const std::string& in) : input(in) {}

Token Lexer::getNextToken() {
    skipWhitespace();
    if (pos >= input.size()) {
        return { TokenType::EOF_TOKEN, "", line, col };
    }

    char c = peekChar();

    // A simple approach for comments, strings, numbers, etc. omitted for brevity

    // IDENTIFIER or KEYWORD
    if (std::isalpha(static_cast<unsigned char>(c))) {
        return identifierOrKeyword();
    }

    // Handle operators like '=' or punctuation like ';' similarly
    // ...
    // Fallthrough => unknown, skip or throw
    pos++;
    col++;
    return { TokenType::UNKNOWN, std::string(1, c), line, col };
}

Token Lexer::identifierOrKeyword() {
    Token token;
    token.line = line;
    token.col = col;
    token.type = TokenType::IDENTIFIER;

    std::string value;
    while (std::isalnum(peekChar()) || peekChar() == '_' || peekChar() == '$') {
        value += getChar();
    }
    // Convert to uppercase for case-insensitive matching
    std::string upperValue = value;
    std::transform(upperValue.begin(), upperValue.end(), upperValue.begin(), ::toupper);

    // Check for known keywords
    if (upperValue == "DATA")      { token.type = TokenType::KEYWORD_DATA; }
    else if (upperValue == "RUN")  { token.type = TokenType::KEYWORD_RUN; }
    else if (upperValue == "OUTPUT") { token.type = TokenType::KEYWORD_OUTPUT; }
    else if (upperValue == "INPUT") { token.type = TokenType::KEYWORD_INPUT; }        // NEW
    else if (upperValue == "DATALINES") { token.type = TokenType::KEYWORD_DATALINES; } // NEW
    // etc...

    token.text = value;
    return token;
}

// ...
```

---

# 2. AST Nodes

We¡¯ll introduce two new node types:

1. **`InputNode`**: holds a list of variables declared in the `INPUT` statement.
2. **`DatalinesNode`**: holds the **raw lines** read until the special terminating `;`.

```cpp
// AST.h (excerpt)
#ifndef AST_H
#define AST_H

#include <string>
#include <vector>
#include <memory>

class ASTNode {
public:
    virtual ~ASTNode() = default;
};

class ExpressionNode : public ASTNode {
    // ...
};

class NumberNode : public ExpressionNode {
public:
    double value;
    explicit NumberNode(double v) : value(v) {}
};

class StringNode : public ExpressionNode {
public:
    std::string value;
    explicit StringNode(const std::string &v) : value(v) {}
};

// data a; ... run;
class DataStepNode : public ASTNode {
public:
    std::string outputDataSet;
    std::vector<std::unique_ptr<ASTNode>> statements;
};

// input var1 var2 ...;
class InputNode : public ASTNode {
public:
    std::vector<std::string> variables;  // e.g. {"name", "age"}
};

// datalines; <lines> ;
class DatalinesNode : public ASTNode {
public:
    std::vector<std::string> lines;  // the raw lines
};

// assignment node, output node, etc. omitted for brevity

#endif // AST_H
```

---

# 3. Parser Logic

We need to parse two new statements inside a DATA step:

1. `INPUT var1 var2 ...;`
2. `DATALINES; <lines> ;`

### 3.1 `parseInput()`

We read `input`, then parse **identifiers** until we see a semicolon.

```cpp
// Parser.cpp (excerpt)
#include "Parser.h"
#include <stdexcept>
#include <sstream>

std::unique_ptr<ASTNode> Parser::parseInput() {
    // we already consumed "input" token
    auto node = std::make_unique<InputNode>();

    // gather variable names until semicolon
    while (true) {
        Token t = peek();
        if (t.type == TokenType::SEMICOLON || t.type == TokenType::EOF_TOKEN) {
            break;
        }
        // Expect an identifier: e.g. name, age, name$
        if (t.type == TokenType::IDENTIFIER) {
            node->variables.push_back(t.text);
            advance(); // consume
        } else {
            throw std::runtime_error("Expected variable name in INPUT statement, got: " + t.text);
        }
    }

    // expect semicolon
    consume(TokenType::SEMICOLON, "Expected ';' after INPUT statement");
    return node;
}
```

### 3.2 `parseDatalines()`

We read `datalines`, then a semicolon, then **all lines** up to a **single semicolon** on its own line (like SAS).  
**In real SAS**, the `datalines;` block ends at either a line with just `;` or the next statement. We¡¯ll do a simplified approach: we look for a semicolon token on its own.

```cpp
std::unique_ptr<ASTNode> Parser::parseDatalines() {
    // we already consumed "datalines" token
    auto node = std::make_unique<DatalinesNode>();

    // expect semicolon
    consume(TokenType::SEMICOLON, "Expected ';' after DATALINES");

    // Now read raw lines until we find a line with a lone semicolon
    while (true) {
        Token t = peek();
        if (t.type == TokenType::EOF_TOKEN) {
            // incomplete or no semicolon => treat as error or incomplete
            throw std::runtime_error("Missing terminating semicolon after DATALINES data.");
        }

        // If it's a semicolon token on a line by itself, break
        // (A real SAS parser might do more advanced checks.)
        // For simplicity, if we see SEMICOLON, we break
        if (t.type == TokenType::SEMICOLON) {
            advance(); // consume the semicolon
            break;
        }

        // Otherwise, treat the entire token line as data?
        // In a real parser, you might store the text raw from the lexer or from the input. 
        // We'll do a simplified approach: each "line" is a single token or so.
        // A more robust approach is to store the raw text from the Lexer or handle line-based logic. 
        node->lines.push_back(t.text);
        advance();
    }

    return node;
}
```

### 3.3 Integrating into `parseStatement()`

Inside your `DataStepNode`, after `data <dataset>;` is read, you parse multiple statements until `run;`. In that loop:

```cpp
std::unique_ptr<ASTNode> Parser::parseStatement() {
    Token t = peek();
    switch (t.type) {
        case TokenType::KEYWORD_INPUT:
            advance(); // consume 'input'
            return parseInput();

        case TokenType::KEYWORD_DATALINES:
            advance(); // consume 'datalines'
            return parseDatalines();

        // handle assignment, output, if, do, etc.

        default:
            throw std::runtime_error("Unknown statement: " + t.text);
    }
}
```

(You already have `parseAssignment()`, `parseOutput()`, etc.)

---

# 4. Interpreter Support

We¡¯ll show **two** new pieces of logic:

1. **`InputNode`**: We store in the `DataStepNode` that these variables should be read from DATALINES. Typically, SAS uses `INPUT` to define the variable names, types, and so on.  
2. **`DatalinesNode`**: The lines themselves are stored. When we reach `run;`, we interpret them by creating rows in the dataset.

### 4.1 Storing Input State in the Data Environment

We might add to the `DataStepNode` an `std::vector<std::string> inputVariables;` or we let the interpreter track it. Here, we interpret them on-the-fly:

```cpp
void Interpreter::executeDataStep(DataStepNode* node) {
    // create dataset, etc.
    // interpret each statement
    std::vector<std::string> inputVars;
    std::vector<std::string> dataLines;

    for (auto &stmt : node->statements) {
        if (auto inp = dynamic_cast<InputNode*>(stmt.get())) {
            // store those variable names
            for (auto &var : inp->variables) {
                inputVars.push_back(var);
            }
        }
        else if (auto dl = dynamic_cast<DatalinesNode*>(stmt.get())) {
            // store raw lines
            for (auto &line : dl->lines) {
                dataLines.push_back(line);
            }
        }
        else if (auto assign = dynamic_cast<AssignmentNode*>(stmt.get())) {
            // etc...
        }
        else if (auto outputStmt = dynamic_cast<OutputNode*>(stmt.get())) {
            // ...
        }
    }

    // After all statements are processed, if we have input variables + datalines,
    // we create rows from them. In real SAS, each dataline gets read into
    // the variables in order. For instance:
    //   input name $ age;
    //   datalines;
    //   john 23
    //   mary 30
    //   ;
    //
    // We'll do a naive parser: each line => tokens => store in row.

    if (!inputVars.empty() && !dataLines.empty()) {
        for (auto &dlLine : dataLines) {
            // split by whitespace (super naive)
            std::istringstream iss(dlLine);
            std::vector<std::string> fields;
            std::string f;
            while (iss >> f) {
                fields.push_back(f);
            }

            Row row;
            for (size_t i = 0; i < inputVars.size() && i < fields.size(); ++i) {
                std::string &varName = inputVars[i];
                std::string &val = fields[i];
                // Suppose we check if varName ends with '$' => string
                // else numeric
                if (!varName.empty() && varName.back() == '$') {
                    // store as string
                    std::string realVarName = varName.substr(0, varName.size()-1);
                    row.columns[realVarName] = val;
                } else {
                    // store numeric
                    try {
                        double d = std::stod(val);
                        row.columns[varName] = d;
                    } catch(...) {
                        row.columns[varName] = std::nan(""); 
                    }
                }
            }
            ds->addRow(row);
        }
    }

    // Then do the note/log messages as usual:
    // logLogger.info("NOTE: The data set ... has ... observations, etc.");
}
```

**This** is quite simplified, but enough to demonstrate how an `INPUT`/`DATALINES` approach might work. Real SAS has more complex rules about `$`, column pointers, informats, etc.

---

# 5. GTest Example

We want to test something like:

```sas
data employees;
  input name $ age;
  datalines;
john 23
mary 30
;
run;
```

**We** expect:
- A new dataset `WORK.employees` with 2 rows.
- `name` = `"john"`, `age` = `23` for the first row; `"mary"`, `30` for the second.

**Test**:

```cpp
// InputDatalinesTest.cpp
#include <gtest/gtest.h>
#include "Lexer.h"
#include "Parser.h"
#include "Interpreter.h"
#include "DataEnvironment.h"

TEST(InputDatalinesTest, BasicRead) {
    std::string code = R"(
        data employees;
            input name $ age;
            datalines;
john 23
mary 30
;
        run;
    )";

    // 1) Lex
    Lexer lexer(code);
    std::vector<Token> tokens;
    Token tok;
    while ((tok = lexer.getNextToken()).type != TokenType::EOF_TOKEN) {
        tokens.push_back(tok);
    }

    // 2) Parse
    Parser parser(tokens);
    std::unique_ptr<ProgramNode> program;
    try {
        program = parser.parseProgram();
    } catch (const std::runtime_error &e) {
        FAIL() << "Parser error: " << e.what();
    }
    ASSERT_TRUE(program != nullptr);

    // 3) Interpret
    DataEnvironment env;
    auto consoleLogger = spdlog::default_logger();
    Interpreter interpreter(env, *consoleLogger, *consoleLogger);

    try {
        interpreter.executeProgram(program);
    } catch (const std::runtime_error &e) {
        FAIL() << "Interpreter error: " << e.what();
    }

    // 4) Check dataset
    auto it = env.dataSets.find("WORK.employees");
    ASSERT_NE(it, env.dataSets.end()) << "Dataset WORK.employees not found.";
    auto ds = it->second;
    ASSERT_EQ(ds->rows.size(), 2u) << "Expected 2 observations.";

    // Check the first row => name="john", age=23
    {
        auto &row = ds->rows[0];
        auto rName = row.columns.find("name");
        auto rAge  = row.columns.find("age");
        ASSERT_TRUE(rName != row.columns.end());
        ASSERT_TRUE(rAge  != row.columns.end());

        ASSERT_TRUE(std::holds_alternative<std::string>(rName->second));
        EXPECT_EQ(std::get<std::string>(rName->second), "john");

        ASSERT_TRUE(std::holds_alternative<double>(rAge->second));
        EXPECT_DOUBLE_EQ(std::get<double>(rAge->second), 23.0);
    }

    // Check second row => name="mary", age=30
    {
        auto &row = ds->rows[1];
        auto rName = row.columns.find("name");
        auto rAge  = row.columns.find("age");
        ASSERT_TRUE(rName != row.columns.end());
        ASSERT_TRUE(rAge  != row.columns.end());

        ASSERT_TRUE(std::holds_alternative<std::string>(rName->second));
        EXPECT_EQ(std::get<std::string>(rName->second), "mary");

        ASSERT_TRUE(std::holds_alternative<double>(rAge->second));
        EXPECT_DOUBLE_EQ(std::get<double>(rAge->second), 30.0);
    }
}
```

Run with `ctest` or `./sass_test`:

```
[ RUN      ] InputDatalinesTest.BasicRead
[       OK ] InputDatalinesTest.BasicRead
```

---

## Putting It All Together

1. **Tokens**: Add `KEYWORD_INPUT` and `KEYWORD_DATALINES`.  
2. **Lexer**: Recognize `input` and `datalines` as new keywords.  
3. **Parser**: 
   - In `parseStatement()`, handle `input` -> `parseInput()`, `datalines` -> `parseDatalines()`.  
   - Inside your `DataStepNode`, store those nodes.  
4. **Interpreter**: 
   - `InputNode` collects variable names;  
   - `DatalinesNode` collects lines;  
   - After the data step finishes, create rows from the lines, using the variable list from `INPUT`.  
5. **Test**: Confirm that a small example (with two lines) produces the correct dataset rows.

This is a **bare-bones** approach. Real SAS supports **more** (e.g., column pointers, informats, `$` to specify char variables, reading multiple lines, error handling). But it should get you started on ¡°in-memory¡± test data generation using `INPUT` and `DATALINES`. Good luck integrating it into your full interpreter!